{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMEngine配置文件-MaskRCNN\n",
    "### 1.模型配置\n",
    "在 mmdetection 的配置中，我们使用 model 字段来配置检测算法的组件。 除了 backbone、neck 等神经网络组件外，还需要 data_preprocessor、train_cfg 和 test_cfg。 data_preprocessor 负责对 dataloader 输出的每一批数据进行预处理。 模型配置中的 train_cfg 和 test_cfg 用于设置训练和测试组件的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    type='MaskRCNN',  # 检测器名\n",
    "    data_preprocessor=dict(  # 数据预处理器的配置，通常包括图像归一化和 padding\n",
    "        type='DetDataPreprocessor',  # 数据预处理器的类型，参考 https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.data_preprocessors.DetDataPreprocessor\n",
    "        mean=[123.675, 116.28, 103.53],  # 用于预训练骨干网络的图像归一化通道均值，按 R、G、B 排序\n",
    "        std=[58.395, 57.12, 57.375],  # 用于预训练骨干网络的图像归一化通道标准差，按 R、G、B 排序\n",
    "        bgr_to_rgb=True,  # 是否将图片通道从 BGR 转为 RGB\n",
    "        pad_mask=True,  # 是否填充实例分割掩码\n",
    "        pad_size_divisor=32),  # padding 后的图像的大小应该可以被 ``pad_size_divisor`` 整除\n",
    "    backbone=dict(  # 主干网络的配置文件\n",
    "        type='ResNet',  # 主干网络的类别，可用选项请参考 https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.backbones.ResNet\n",
    "        depth=50,  # 主干网络的深度，对于 ResNet 和 ResNext 通常设置为 50 或 101\n",
    "        num_stages=4,  # 主干网络状态(stages)的数目，这些状态产生的特征图作为后续的 head 的输入\n",
    "        out_indices=(0, 1, 2, 3),  # 每个状态产生的特征图输出的索引\n",
    "        frozen_stages=1,  # 第一个状态的权重被冻结\n",
    "        norm_cfg=dict(  # 归一化层(norm layer)的配置项\n",
    "            type='BN',  # 归一化层的类别，通常是 BN 或 GN\n",
    "            requires_grad=True),  # 是否训练归一化里的 gamma 和 beta\n",
    "        norm_eval=True,  # 是否冻结 BN 里的统计项\n",
    "        style='pytorch',  # 主干网络的风格，'pytorch' 意思是步长为2的层为 3x3 卷积， 'caffe' 意思是步长为2的层为 1x1 卷积\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),  # 加载通过 ImageNet 预训练的模型\n",
    "    neck=dict(\n",
    "        type='FPN',  # 检测器的 neck 是 FPN，我们同样支持 'NASFPN', 'PAFPN' 等，更多细节可以参考 https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.necks.FPN\n",
    "        in_channels=[256, 512, 1024, 2048],  # 输入通道数，这与主干网络的输出通道一致\n",
    "        out_channels=256,  # 金字塔特征图每一层的输出通道\n",
    "        num_outs=5),  # 输出的范围(scales)\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',  # rpn_head 的类型是 'RPNHead', 我们也支持 'GARPNHead' 等，更多细节可以参考 https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.dense_heads.RPNHead\n",
    "        in_channels=256,  # 每个输入特征图的输入通道，这与 neck 的输出通道一致\n",
    "        feat_channels=256,  # head 卷积层的特征通道\n",
    "        anchor_generator=dict(  # 锚点(Anchor)生成器的配置\n",
    "            type='AnchorGenerator',  # 大多数方法使用 AnchorGenerator 作为锚点生成器, SSD 检测器使用 `SSDAnchorGenerator`。更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/prior_generators/anchor_generator.py#L18\n",
    "            scales=[8],  # 锚点的基本比例，特征图某一位置的锚点面积为 scale * base_sizes\n",
    "            ratios=[0.5, 1.0, 2.0],  # 高度和宽度之间的比率\n",
    "            strides=[4, 8, 16, 32, 64]),  # 锚生成器的步幅。这与 FPN 特征步幅一致。 如果未设置 base_sizes，则当前步幅值将被视为 base_sizes\n",
    "        bbox_coder=dict(  # 在训练和测试期间对框进行编码和解码\n",
    "            type='DeltaXYWHBBoxCoder',  # 框编码器的类别，'DeltaXYWHBBoxCoder' 是最常用的，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py#L13\n",
    "            target_means=[0.0, 0.0, 0.0, 0.0],  # 用于编码和解码框的目标均值\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),  # 用于编码和解码框的标准差\n",
    "        loss_cls=dict(  # 分类分支的损失函数配置\n",
    "            type='CrossEntropyLoss',  # 分类分支的损失类型，我们也支持 FocalLoss 等，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/losses/cross_entropy_loss.py#L201\n",
    "            use_sigmoid=True,  # RPN 通常进行二分类，所以通常使用 sigmoid 函数\n",
    "            los_weight=1.0),  # 分类分支的损失权重\n",
    "        loss_bbox=dict(  # 回归分支的损失函数配置\n",
    "            type='L1Loss',  # 损失类型，我们还支持许多 IoU Losses 和 Smooth L1-loss 等，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/losses/smooth_l1_loss.py#L56\n",
    "            loss_weight=1.0)),  # 回归分支的损失权重\n",
    "    roi_head=dict(  # RoIHead 封装了两步(two-stage)/级联(cascade)检测器的第二步\n",
    "        type='StandardRoIHead',  # RoI head 的类型，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/roi_heads/standard_roi_head.py#L17\n",
    "        bbox_roi_extractor=dict(  # 用于 bbox 回归的 RoI 特征提取器\n",
    "            type='SingleRoIExtractor',  # RoI 特征提取器的类型，大多数方法使用 SingleRoIExtractor，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py#L13\n",
    "            roi_layer=dict(  # RoI 层的配置\n",
    "                type='RoIAlign',  # RoI 层的类别, 也支持 DeformRoIPoolingPack 和 ModulatedDeformRoIPoolingPack，更多细节请参考 https://mmcv.readthedocs.io/en/latest/api.html#mmcv.ops.RoIAlign\n",
    "                output_size=7,  # 特征图的输出大小\n",
    "                sampling_ratio=0),  # 提取 RoI 特征时的采样率。0 表示自适应比率\n",
    "            out_channels=256,  # 提取特征的输出通道\n",
    "            featmap_strides=[4, 8, 16, 32]),  # 多尺度特征图的步幅，应该与主干的架构保持一致\n",
    "        bbox_head=dict(  # RoIHead 中 box head 的配置\n",
    "            type='Shared2FCBBoxHead',  # bbox head 的类别，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py#L220\n",
    "            in_channels=256,  # bbox head 的输入通道。 这与 roi_extractor 中的 out_channels 一致\n",
    "            fc_out_channels=1024,  # FC 层的输出特征通道\n",
    "            roi_feat_size=7,  # 候选区域(Region of Interest)特征的大小\n",
    "            num_classes=80,  # 分类的类别数量\n",
    "            bbox_coder=dict(  # 第二阶段使用的框编码器\n",
    "                type='DeltaXYWHBBoxCoder',  # 框编码器的类别，大多数情况使用 'DeltaXYWHBBoxCoder'\n",
    "                target_means=[0.0, 0.0, 0.0, 0.0],  # 用于编码和解码框的均值\n",
    "                target_stds=[0.1, 0.1, 0.2, 0.2]),  # 编码和解码的标准差。因为框更准确，所以值更小，常规设置时 [0.1, 0.1, 0.2, 0.2]。\n",
    "            reg_class_agnostic=False,  # 回归是否与类别无关\n",
    "            loss_cls=dict(  # 分类分支的损失函数配\n",
    "                type='CrossEntropyLoss',  # 分类分支的损失类型，我们也支持 FocalLoss 等\n",
    "                use_sigmoid=False,  # 是否使用 sigmoid\n",
    "                loss_weight=1.0),  # 分类分支的损失权重\n",
    "            loss_bbox=dict(  # 回归分支的损失函数配置\n",
    "                type='L1Loss',  # 损失类型，我们还支持许多 IoU Losses 和 Smooth L1-loss 等\n",
    "                loss_weight=1.0)),  # 回归分支的损失权重\n",
    "        mask_roi_extractor=dict(  # 用于 mask 生成的 RoI 特征提取器\n",
    "            type='SingleRoIExtractor',  # RoI 特征提取器的类型，大多数方法使用 SingleRoIExtractor\n",
    "            roi_layer=dict(  # 提取实例分割特征的 RoI 层配置\n",
    "                type='RoIAlign',  # RoI 层的类型，也支持 DeformRoIPoolingPack 和 ModulatedDeformRoIPoolingPack\n",
    "                output_size=14,  # 特征图的输出大小\n",
    "                sampling_ratio=0),  # 提取 RoI 特征时的采样率\n",
    "            out_channels=256,  # 提取特征的输出通道\n",
    "            featmap_strides=[4, 8, 16, 32]),  # 多尺度特征图的步幅\n",
    "        mask_head=dict(  # mask 预测 head 模型\n",
    "            type='FCNMaskHead',  # mask head 的类型，更多细节请参考 https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.roi_heads.FCNMaskHead\n",
    "            num_convs=4,  # mask head 中的卷积层数\n",
    "            in_channels=256,  # 输入通道，应与 mask roi extractor 的输出通道一致\n",
    "            conv_out_channels=256,  # 卷积层的输出通道\n",
    "            num_classes=80,  # 要分割的类别数\n",
    "            loss_mask=dict(  # mask 分支的损失函数配置\n",
    "                type='CrossEntropyLoss',  # 用于分割的损失类型\n",
    "                use_mask=True,  # 是否只在正确的类中训练 mask\n",
    "                loss_weight=1.0))),  # mask 分支的损失权重\n",
    "    train_cfg = dict(  # rpn 和 rcnn 训练超参数的配置\n",
    "        rpn=dict(  # rpn 的训练配置\n",
    "            assigner=dict(  # 分配器(assigner)的配置\n",
    "                type='MaxIoUAssigner',  # 分配器的类型，MaxIoUAssigner 用于许多常见的检测器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/assigners/max_iou_assigner.py#L14\n",
    "                pos_iou_thr=0.7,  # IoU >= 0.7(阈值) 被视为正样本\n",
    "                neg_iou_thr=0.3,  # IoU < 0.3(阈值) 被视为负样本\n",
    "                min_pos_iou=0.3,  # 将框作为正样本的最小 IoU 阈值\n",
    "                match_low_quality=True,  # 是否匹配低质量的框(更多细节见 API 文档)\n",
    "                ignore_iof_thr=-1),  # 忽略 bbox 的 IoF 阈值\n",
    "            sampler=dict(  # 正/负采样器(sampler)的配置\n",
    "                type='RandomSampler',  # 采样器类型，还支持 PseudoSampler 和其他采样器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/samplers/random_sampler.py#L14\n",
    "                num=256,  # 样本数量。\n",
    "                pos_fraction=0.5,  # 正样本占总样本的比例\n",
    "                neg_pos_ub=-1,  # 基于正样本数量的负样本上限\n",
    "                add_gt_as_proposals=False),  # 采样后是否添加 GT 作为 proposal\n",
    "            allowed_border=-1,  # 填充有效锚点后允许的边框\n",
    "            pos_weight=-1,  # 训练期间正样本的权重\n",
    "            debug=False),  # 是否设置调试(debug)模式\n",
    "        rpn_proposal=dict(  # 在训练期间生成 proposals 的配置\n",
    "            nms_across_levels=False,  # 是否对跨层的 box 做 NMS。仅适用于 `GARPNHead` ，naive rpn 不支持 nms cross levels\n",
    "            nms_pre=2000,  # NMS 前的 box 数\n",
    "            nms_post=1000,  # NMS 要保留的 box 的数量，只在 GARPNHHead 中起作用\n",
    "            max_per_img=1000,  # NMS 后要保留的 box 数量\n",
    "            nms=dict( # NMS 的配置\n",
    "                type='nms',  # NMS 的类别\n",
    "                iou_threshold=0.7 # NMS 的阈值\n",
    "                ),\n",
    "            min_bbox_size=0),  # 允许的最小 box 尺寸\n",
    "        rcnn=dict(  # roi head 的配置。\n",
    "            assigner=dict(  # 第二阶段分配器的配置，这与 rpn 中的不同\n",
    "                type='MaxIoUAssigner',  # 分配器的类型，MaxIoUAssigner 目前用于所有 roi_heads。更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/assigners/max_iou_assigner.py#L14\n",
    "                pos_iou_thr=0.5,  # IoU >= 0.5(阈值)被认为是正样本\n",
    "                neg_iou_thr=0.5,  # IoU < 0.5(阈值)被认为是负样本\n",
    "                min_pos_iou=0.5,  # 将 box 作为正样本的最小 IoU 阈值\n",
    "                match_low_quality=False,  # 是否匹配低质量下的 box(有关更多详细信息，请参阅 API 文档)\n",
    "                ignore_iof_thr=-1),  # 忽略 bbox 的 IoF 阈值\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',  # 采样器的类型，还支持 PseudoSampler 和其他采样器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/samplers/random_sampler.py#L14\n",
    "                num=512,  # 样本数量\n",
    "                pos_fraction=0.25,  # 正样本占总样本的比例\n",
    "                neg_pos_ub=-1,  # 基于正样本数量的负样本上限\n",
    "                add_gt_as_proposals=True\n",
    "            ),  # 采样后是否添加 GT 作为 proposal\n",
    "            mask_size=28,  # mask 的大小\n",
    "            pos_weight=-1,  # 训练期间正样本的权重\n",
    "            debug=False)),  # 是否设置调试模式\n",
    "    test_cfg = dict(  # 用于测试 rpn 和 rcnn 超参数的配置\n",
    "        rpn=dict(  # 测试阶段生成 proposals 的配置\n",
    "            nms_across_levels=False,  # 是否对跨层的 box 做 NMS。仅适用于 `GARPNHead`，naive rpn 不支持做 NMS cross levels\n",
    "            nms_pre=1000,  # NMS 前的 box 数\n",
    "            nms_post=1000,  # NMS 要保留的 box 的数量，只在 `GARPNHHead` 中起作用\n",
    "            max_per_img=1000,  # NMS 后要保留的 box 数量\n",
    "            nms=dict( # NMS 的配置\n",
    "                type='nms',  # NMS 的类型\n",
    "                iou_threshold=0.7 # NMS 阈值\n",
    "                ),\n",
    "            min_bbox_size=0),  # box 允许的最小尺寸\n",
    "        rcnn=dict(  # roi heads 的配置\n",
    "            score_thr=0.05,  # bbox 的分数阈值\n",
    "            nms=dict(  # 第二步的 NMS 配置\n",
    "                type='nms',  # NMS 的类型\n",
    "                iou_thr=0.5),  # NMS 的阈值\n",
    "            max_per_img=100,  # 每张图像的最大检测次数\n",
    "            mask_thr_binary=0.5)))  # mask 预处的阈值"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据集和评测器配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = [  # 训练数据处理流程\n",
    "    dict(type='LoadImageFromFile'),  # 第 1 个流程，从文件路径里加载图像。\n",
    "    dict(\n",
    "        type='LoadAnnotations',  # 第 2 个流程，对于当前图像，加载它的注释信息。\n",
    "        with_bbox=True,  # 是否使用标注框(bounding box)， 目标检测需要设置为 True。\n",
    "        with_mask=True,  # 是否使用 instance mask，实例分割需要设置为 True。\n",
    "        poly2mask=False),  # 是否将 polygon mask 转化为 instance mask, 设置为 False 以加速和节省内存。\n",
    "    dict(\n",
    "        type='Resize',  # 变化图像和其标注大小的流程。\n",
    "        scale=(1333, 800),  # 图像的最大尺寸\n",
    "        keep_ratio=True  # 是否保持图像的长宽比。\n",
    "        ),\n",
    "    dict(\n",
    "        type='RandomFlip',  # 翻转图像和其标注的数据增广流程。\n",
    "        prob=0.5),  # 翻转图像的概率。\n",
    "    dict(type='PackDetInputs')  # 将数据转换为检测器输入格式的流程\n",
    "]\n",
    "test_pipeline = [  # 测试数据处理流程\n",
    "    dict(type='LoadImageFromFile'),  # 第 1 个流程，从文件路径里加载图像。\n",
    "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),  # 变化图像大小的流程。\n",
    "    dict(\n",
    "        type='PackDetInputs',  # 将数据转换为检测器输入格式的流程\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor'))\n",
    "]\n",
    "train_dataloader = dict(  # 训练 dataloader 配置\n",
    "    batch_size=2,  # 单个 GPU 的 batch size\n",
    "    num_workers=2,  # 单个 GPU 分配的数据加载线程数\n",
    "    persistent_workers=True,  # 如果设置为 True，dataloader 在迭代完一轮之后不会关闭数据读取的子进程，可以加速训练\n",
    "    sampler=dict(  # 训练数据的采样器\n",
    "        type='DefaultSampler',  # 默认的采样器，同时支持分布式和非分布式训练。请参考 https://mmengine.readthedocs.io/zh_CN/latest/api/generated/mmengine.dataset.DefaultSampler.html#mmengine.dataset.DefaultSampler\n",
    "        shuffle=True),  # 随机打乱每个轮次训练数据的顺序\n",
    "    batch_sampler=dict(type='AspectRatioBatchSampler'),  # 批数据采样器，用于确保每一批次内的数据拥有相似的长宽比，可用于节省显存\n",
    "    dataset=dict(  # 训练数据集的配置\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file='annotations/instances_train2017.json',  # 标注文件路径\n",
    "        data_prefix=dict(img='train2017/'),  # 图片路径前缀\n",
    "        filter_cfg=dict(filter_empty_gt=True, min_size=32),  # 图片和标注的过滤配置\n",
    "        pipeline=train_pipeline))  # 这是由之前创建的 train_pipeline 定义的数据处理流程。\n",
    "val_dataloader = dict(  # 验证 dataloader 配置\n",
    "    batch_size=1,  # 单个 GPU 的 Batch size。如果 batch-szie > 1，组成 batch 时的额外填充会影响模型推理精度\n",
    "    num_workers=2,  # 单个 GPU 分配的数据加载线程数\n",
    "    persistent_workers=True,  # 如果设置为 True，dataloader 在迭代完一轮之后不会关闭数据读取的子进程，可以加速训练\n",
    "    drop_last=False,  # 是否丢弃最后未能组成一个批次的数据\n",
    "    sampler=dict(\n",
    "        type='DefaultSampler',\n",
    "        shuffle=False),  # 验证和测试时不打乱数据顺序\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file='annotations/instances_val2017.json',\n",
    "        data_prefix=dict(img='val2017/'),\n",
    "        test_mode=True,  # 开启测试模式，避免数据集过滤图片和标注\n",
    "        pipeline=test_pipeline))\n",
    "test_dataloader = val_dataloader  # 测试 dataloader 配置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.评测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_evaluator = dict(  # 验证过程使用的评测器\n",
    "    type='CocoMetric',  # 用于评估检测和实例分割的 AR、AP 和 mAP 的 coco 评价指标\n",
    "    ann_file=data_root + 'annotations/instances_val2017.json',  # 标注文件路径\n",
    "    metric=['bbox', 'segm'],  # 需要计算的评价指标，`bbox` 用于检测，`segm` 用于实例分割\n",
    "    format_only=False)\n",
    "test_evaluator = val_evaluator  # 测试过程使用的评测器\n",
    "# 由于测试数据集没有标注文件，因此 MMDetection 中的 test_dataloader 和 test_evaluator 配置通常等于val。 如果要保存在测试数据集上的检测结果，则可以像这样编写配置：\n",
    "# 在测试集上推理，\n",
    "# 并将检测结果转换格式以用于提交结果\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "        data_prefix=dict(img='test2017/'),\n",
    "        test_mode=True,\n",
    "        pipeline=test_pipeline))\n",
    "test_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "    metric=['bbox', 'segm'],\n",
    "    format_only=True,  # 只将模型输出转换为 coco 的 JSON 格式并保存\n",
    "    outfile_prefix='./work_dirs/coco_detection/test')  # 要保存的 JSON 文件的前缀"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.训练和测试的配置\n",
    "MMEngine 的 Runner 使用 Loop 来控制训练，验证和测试过程。 用户可以使用这些字段设置最大训练轮次和验证间隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',  # 训练循环的类型，请参考 https://github.com/open-mmlab/mmengine/blob/main/mmengine/runner/loops.py\n",
    "    max_epochs=12,  # 最大训练轮次\n",
    "    val_interval=1)  # 验证间隔。每个 epoch 验证一次\n",
    "val_cfg = dict(type='ValLoop')  # 验证循环的类型\n",
    "test_cfg = dict(type='TestLoop')  # 测试循环的类型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.优化相关配置\n",
    "optim_wrapper 是配置优化相关设置的字段。优化器封装（OptimWrapper）不仅提供了优化器的功能，还支持梯度裁剪、混合精度训练等功能。更多内容请看优化器封装教程 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_wrapper = dict(  # 优化器封装的配置\n",
    "    type='OptimWrapper',  # 优化器封装的类型。可以切换至 AmpOptimWrapper 来启用混合精度训练\n",
    "    optimizer=dict(  # 优化器配置。支持 PyTorch 的各种优化器。请参考 https://pytorch.org/docs/stable/optim.html#algorithms\n",
    "        type='SGD',  # 随机梯度下降优化器\n",
    "        lr=0.02,  # 基础学习率\n",
    "        momentum=0.9,  # 带动量的随机梯度下降\n",
    "        weight_decay=0.0001),  # 权重衰减\n",
    "    clip_grad=None,  # 梯度裁剪的配置，设置为 None 关闭梯度裁剪。使用方法请见 https://mmengine.readthedocs.io/en/latest/tutorials/optimizer.html\n",
    "    )\n",
    "# param_scheduler 字段用于配置参数调度器（Parameter Scheduler）来调整优化器的超参数（例如学习率和动量）。 用户可以组合多个调度器来创建所需的参数调整策略。 在 参数调度器教程 和 参数调度器 API 文档 中查找更多信息。\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR',  # 使用线性学习率预热\n",
    "        start_factor=0.001, # 学习率预热的系数\n",
    "        by_epoch=False,  # 按 iteration 更新预热学习率\n",
    "        begin=0,  # 从第一个 iteration 开始\n",
    "        end=500),  # 到第 500 个 iteration 结束\n",
    "    dict(\n",
    "        type='MultiStepLR',  # 在训练过程中使用 multi step 学习率策略\n",
    "        by_epoch=True,  # 按 epoch 更新学习率\n",
    "        begin=0,   # 从第一个 epoch 开始\n",
    "        end=12,  # 到第 12 个 epoch 结束\n",
    "        milestones=[8, 11],  # 在哪几个 epoch 进行学习率衰减\n",
    "        gamma=0.1)  # 学习率衰减系数\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.钩子配置\n",
    "用户可以在训练、验证和测试循环上添加钩子，以便在运行期间插入一些操作。配置中有两种不同的钩子字段，一种是 default_hooks，另一种是 custom_hooks。\n",
    "default_hooks 是一个字典，用于配置运行时必须使用的钩子。这些钩子具有默认优先级，如果未设置，runner 将使用默认值。如果要禁用默认钩子，用户可以将其配置设置为 None。更多内容请看 钩子教程 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_hooks = dict(\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "    logger=dict(type='LoggerHook', interval=50),\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "    visualization=dict(type='DetVisualizationHook'))\n",
    "# custom_hooks 是一个列表。用户可以在这个字段中加入自定义的钩子。\n",
    "custom_hooks = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.运行相关配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scope = 'mmdet'  # 默认的注册器域名，默认从此注册器域中寻找模块。请参考 https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/registry.html\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=False,  # 是否启用 cudnn benchmark\n",
    "    mp_cfg=dict(  # 多进程设置\n",
    "        mp_start_method='fork',  # 使用 fork 来启动多进程。'fork' 通常比 'spawn' 更快，但可能存在隐患。请参考 https://github.com/pytorch/pytorch/issues/1355\n",
    "        opencv_num_threads=0),  # 关闭 opencv 的多线程以避免系统超负荷\n",
    "    dist_cfg=dict(backend='nccl'),  # 分布式相关设置\n",
    ")\n",
    "vis_backends = [dict(type='LocalVisBackend')]  # 可视化后端，请参考 https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/visualization.html\n",
    "visualizer = dict(\n",
    "    type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')\n",
    "log_processor = dict(\n",
    "    type='LogProcessor',  # 日志处理器用于处理运行时日志\n",
    "    window_size=50,  # 日志数值的平滑窗口\n",
    "    by_epoch=True)  # 是否使用 epoch 格式的日志。需要与训练循环的类型保存一致。\n",
    "log_level = 'INFO'  # 日志等级\n",
    "load_from = None  # 从给定路径加载模型检查点作为预训练模型。这不会恢复训练。\n",
    "resume = False  # 是否从 `load_from` 中定义的检查点恢复。 如果 `load_from` 为 None，它将恢复 `work_dir` 中的最新检查点。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Iter-based 配置\n",
    "MMEngine 的 Runner 除了基于轮次的训练循环（epoch）外，还提供了基于迭代（iteration）的训练循环。 要使用基于迭代的训练，用户应该修改 train_cfg、param_scheduler、train_dataloader、default_hooks 和 log_processor。 以下是将基于 epoch 的 RetinaNet 配置更改为基于 iteration 的示例：configs/retinanet/retinanet_r50_fpn_90k_coco.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter-based 训练配置\n",
    "train_cfg = dict(\n",
    "    _delete_=True,  # 忽略继承的配置文件中的值（可选）\n",
    "    type='IterBasedTrainLoop',  # iter-based 训练循环\n",
    "    max_iters=90000,  # 最大迭代次数\n",
    "    val_interval=10000)  # 每隔多少次进行一次验证\n",
    "# 将参数调度器修改为 iter-based\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
    "    dict(\n",
    "        type='MultiStepLR',\n",
    "        begin=0,\n",
    "        end=90000,\n",
    "        by_epoch=False,\n",
    "        milestones=[60000, 80000],\n",
    "        gamma=0.1)\n",
    "]\n",
    "# 切换至 InfiniteSampler 来避免 dataloader 重启\n",
    "train_dataloader = dict(sampler=dict(type='InfiniteSampler'))\n",
    "# 将模型检查点保存间隔设置为按 iter 保存\n",
    "default_hooks = dict(checkpoint=dict(by_epoch=False, interval=10000))\n",
    "# 将日志格式修改为 iter-based\n",
    "log_processor = dict(by_epoch=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.配置文件继承\n",
    "在 config/_base_ 文件夹下有 4 个基本组件类型，分别是：数据集(dataset)，模型(model)，训练策略(schedule)和运行时的默认设置(default runtime)。许多方法，例如 Faster R-CNN、Mask R-CNN、Cascade R-CNN、RPN、SSD 能够很容易地构建出来。由 _base_ 下的组件组成的配置，被我们称为 原始配置(primitive)。  \n",
    "对于同一文件夹下的所有配置，推荐只有一个对应的原始配置文件。所有其他的配置文件都应该继承自这个原始配置文件。这样就能保证配置文件的最大继承深度为 3。  \n",
    "为了便于理解，我们建议贡献者继承现有方法。例如，如果在 Faster R-CNN 的基础上做了一些修改，用户首先可以通过指定 _base_ = ../faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py 来继承基础的 Faster R-CNN 结构，然后修改配置文件中的必要参数以完成继承。  \n",
    "如果你在构建一个与任何现有方法不共享结构的全新方法，那么可以在 configs 文件夹下创建一个新的例如 xxx_rcnn 文件夹。  \n",
    "检查配置文件，可以通过运行 python tools/misc/print_config.py /PATH/TO/CONFIG   \n",
    "有不同的字段，需要使用 _delete_=True 将新的键去替换 backbone 域内所有老的键。  \n",
    "命名规则：r50-caffe_fpn_gn-head 表示在算法中使用 caffe 版本的 ResNet50、FPN 和 使用了 Group Norm 的检测头。8xb4-mixup-giou-coslr-100e 表示使用 8 个 gpu 每个 gpu 4 张图、mixup 数据增强、GIoU loss、余弦退火学习率，并训练 100 个 epoch。1x 和 2x 分别代表 12 epoch 和 24 epoch，20e 在级联模型中使用，表示 20 epoch。  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MYYOLO配置文件\n",
    "目前 MMYOLO 原始配置文件夹 _base_ 中仅包含 default_runtime.py。随着更多算法和多任务的加入，后期会和 MMDet 一样，加入 datasets 等文件夹，方便用户复用。  \n",
    "_base_ 同级目录就是各个算法的配置文件。  \n",
    "{算法名}_{组件名 [组件1]_[组件2]_[...]}-[版本号]_[标准化]_[预处理]_{训练设置}_{训练数据集}_{测试数据集}.py。{} 表示必填部分，[] 表示选填部分。  \n",
    "以 yolov5_s-v61_syncbn_8xb16-300e_coco.py 为例，yolov5_s代表其深度缩放因子deepen_factor=0.33 以及其宽度缩放因子 widen_factor=0.5。YOLOv5 的 6.0 以后的版本采用 6x6 Conv 层作为第一个下采样层，而 3.0 版本采用 Focus 层作为第一个下采样层。8xb16-300e_coco 表示使用 8 个 gpu 每个 gpu 16 张图，并训练 300 个 epoch。不标 fast 默认使用 mmdet.DetDataPreprocessor，而 fast 表示调用 YOLOv5DetDataPreprocessor 并配合 yolov5_collate 进行数据预处理，训练速度较快（不慢于yolov5官方），但是对多任务处理的灵活性较低。  \n",
    "MMYOLO 采用模块化设计，所有功能的模块都可以通过配置文件进行配置。 同样以 yolov5_s-v61_syncbn_8xb16-300e_coco.py 为例，我们将根据不同的功能模块介绍配置文件中的各个字段：\n",
    "我们推荐在配置文件中单独定义这些参数。这些参数实际上是中间变量。  \n",
    "### 1.模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_scale = (640, 640)            # 高度，宽度  \n",
    "deepen_factor = 0.33              # 控制网络结构深度的缩放因子，YOLOv5-s 为 0.33  \n",
    "widen_factor = 0.5                # 控制网络结构宽度的缩放因子，YOLOv5-s 为 0.5  \n",
    "max_epochs = 300                  # 最大训练轮次 300 轮  \n",
    "save_epoch_intervals = 10         # 验证间隔，每 10 个 epoch 验证一次  \n",
    "train_batch_size_per_gpu = 16     # 训练时单个 GPU 的 Batch size  \n",
    "train_num_workers = 8             # 训练时单个 GPU 分配的数据加载线程数  \n",
    "val_batch_size_per_gpu = 1        # 验证时单个 GPU 的 Batch size  \n",
    "val_num_workers = 2               # 验证时单个 GPU 分配的数据加载线程数  \n",
    "\n",
    "anchors = [[(10, 13), (16, 30), (33, 23)], # 多尺度的先验框基本尺寸 \n",
    "           [(30, 61), (62, 45), (59, 119)],\n",
    "           [(116, 90), (156, 198), (373, 326)]]\n",
    "strides = [8, 16, 32] # 先验框生成器的步幅\n",
    "model = dict(\n",
    "    type='YOLODetector', #检测器名\n",
    "    data_preprocessor=dict(  # 数据预处理器的配置，通常包括图像归一化和 padding\n",
    "        type='mmdet.DetDataPreprocessor',  # 数据预处理器的类型，还可以选择 'YOLOv5DetDataPreprocessor' 训练速度更快\n",
    "        mean=[0., 0., 0.],  # 用于预训练骨干网络的图像归一化通道均值，按 R、G、B 排序\n",
    "        std=[255., 255., 255.], # 用于预训练骨干网络的图像归一化通道标准差，按 R、G、B 排序\n",
    "        bgr_to_rgb=True),  # 是否将图像通道从 BGR 转为 RGB\n",
    "    backbone=dict(  # 主干网络的配置文件\n",
    "        type='YOLOv5CSPDarknet',  # 主干网络的类别，目前可选用 'YOLOv5CSPDarknet', 'YOLOv6EfficientRep', 'YOLOXCSPDarknet' 3种\n",
    "        deepen_factor=deepen_factor, # 控制网络结构深度的缩放因子\n",
    "        widen_factor=widen_factor, # 控制网络结构宽度的缩放因子\n",
    "        norm_cfg=dict(type='BN', momentum=0.03, eps=0.001), # 归一化层(norm layer)的配置项\n",
    "        act_cfg=dict(type='SiLU', inplace=True)), # 激活函数(activation function)的配置项\n",
    "    neck=dict(\n",
    "        type='YOLOv5PAFPN',  # 检测器的 neck 是 YOLOv5FPN，我们同样支持 'YOLOv6RepPAFPN', 'YOLOXPAFPN'\n",
    "        deepen_factor=deepen_factor, # 控制网络结构深度的缩放因子\n",
    "        widen_factor=widen_factor, # 控制网络结构宽度的缩放因子\n",
    "        in_channels=[256, 512, 1024], # 输入通道数，与 Backbone 的输出通道一致\n",
    "        out_channels=[256, 512, 1024], # 输出通道数，与 Head 的输入通道一致\n",
    "        num_csp_blocks=3, # CSPLayer 中 bottlenecks 的数量\n",
    "        norm_cfg=dict(type='BN', momentum=0.03, eps=0.001), # 归一化层(norm layer)的配置项\n",
    "        act_cfg=dict(type='SiLU', inplace=True)), # 激活函数(activation function)的配置项\n",
    "    bbox_head=dict(\n",
    "        type='YOLOv5Head', # bbox_head 的类型是 'YOLOv5Head', 我们目前也支持 'YOLOv6Head', 'YOLOXHead'\n",
    "        head_module=dict(\n",
    "            type='YOLOv5HeadModule', # head_module 的类型是 'YOLOv5HeadModule', 我们目前也支持 'YOLOv6HeadModule', 'YOLOXHeadModule'\n",
    "            num_classes=80, # 分类的类别数量\n",
    "            in_channels=[256, 512, 1024], # 输入通道数，与 Neck 的输出通道一致\n",
    "            widen_factor=widen_factor, # 控制网络结构宽度的缩放因子\n",
    "            featmap_strides=[8, 16, 32], # 多尺度特征图的步幅\n",
    "            num_base_priors=3), # 在一个点上，先验框的数量\n",
    "        prior_generator=dict( # 先验框(prior)生成器的配置\n",
    "            type='mmdet.YOLOAnchorGenerator', # 先验框生成器的类型是 mmdet 中的 'YOLOAnchorGenerator'\n",
    "            base_sizes=anchors, # 多尺度的先验框基本尺寸\n",
    "            strides=strides), # 先验框生成器的步幅, 与 FPN 特征步幅一致。如果未设置 base_sizes，则当前步幅值将被视为 base_sizes。\n",
    "    ),\n",
    "    test_cfg=dict(\n",
    "        multi_label=True, # 对于多类别预测来说是否考虑多标签，默认设置为 True\n",
    "        nms_pre=30000,  # NMS 前保留的最大检测框数目\n",
    "        score_thr=0.001, # 过滤类别的分值，低于 score_thr 的检测框当做背景处理\n",
    "        nms=dict(type='nms', # NMS 的类型\n",
    "                 iou_threshold=0.65), # NMS 的阈值\n",
    "        max_per_img=300)) # 每张图像 NMS 后保留的最大检测框数目"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据集和评测器配置\n",
    "在使用 执行器 进行训练、测试、验证时，我们需要配置 Dataloader 。构建数据 dataloader 需要设置数据集（dataset）和数据处理流程（data pipeline）。 由于这部分的配置较为复杂，我们使用中间变量来简化 dataloader 配置的编写。由于 MMYOLO 中各类轻量目标检测算法使用了更加复杂的数据增强方法，因此会比 MMDetection 中的其他模型拥有更多样的数据集配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'CocoDataset'  # 数据集类型，这将被用来定义数据集 \n",
    "data_root = 'data/coco/'  # 数据的根路径\n",
    "file_client_args = dict(backend='disk')  # 文件读取后端的配置，默认从硬盘读取\n",
    "pre_transform = [ # 训练数据读取流程\n",
    "    dict(\n",
    "        type='LoadImageFromFile', # 第 1 个流程，从文件路径里加载图像\n",
    "        file_client_args=file_client_args),  # 文件读取后端的配置，默认从硬盘读取\n",
    "    dict(type='LoadAnnotations', # 第 2 个流程，对于当前图像，加载它的注释信息\n",
    "         with_bbox=True) # 是否使用标注框(bounding box)，目标检测需要设置为 True\n",
    "]\n",
    "albu_train_transforms = [#YOLOv5-v6.1仓库中，引入了Albumentation代码库进行图像数据增广,请确保版本1.0.+\n",
    "    dict(type='Blur', p=0.01),       # 图像模糊，模糊概率 0.01\n",
    "    dict(type='MedianBlur', p=0.01), # 均值模糊，模糊概率 0.01\n",
    "    dict(type='ToGray', p=0.01),         # 随机转换为灰度图像，转灰度概率 0.01\n",
    "dict(type='CLAHE', p=0.01)  # CLAHE(限制对比度自适应直方图均衡化) 图像增强方法，直方图均衡化概率 0.01\n",
    "]\n",
    "train_pipeline = [                # 训练数据处理流程\n",
    "    \t*pre_transform,              # 引入前述定义的训练数据读取流程\n",
    "    \tdict(\n",
    "        \t\ttype='Mosaic',          # Mosaic 数据增强方法\n",
    "        \t\timg_scale=img_scale,    # Mosaic 数据增强后的图像尺寸\n",
    "        \t\tpad_val=114.0,          # 空区域填充像素值\n",
    "        \t\tpre_transform=pre_transform), # 之前创建的 pre_transform 训练数据读取流程\n",
    "    \tdict(\n",
    "        \t\ttype='YOLOv5RandomAffine',      # YOLOv5 的随机仿射变换\n",
    "        \t\tmax_rotate_degree=0.0,          # 最大旋转角度\n",
    "        \t\tmax_shear_degree=0.0,           # 最大错切角度\n",
    "        \t\tscaling_ratio_range=(0.5, 1.5), # 图像缩放系数的范围\n",
    "        \t\tborder=(-img_scale[0] // 2, -img_scale[1] // 2), # 从输入图像的高度和宽度两侧调整输出形状的距离\n",
    "        \t\tborder_val=(114, 114, 114)), # 边界区域填充像素值\n",
    "    \tdict(\n",
    "        \t\ttype='mmdet.Albu',                        # mmdet 中的 Albumentation 数据增强\n",
    "        \t\ttransforms=albu_train_transforms, # 之前创建的 albu_train_transforms 数据增强流程\n",
    "        \t\tbbox_params=dict(\n",
    "            \ttype='BboxParams',\n",
    "            \tformat='pascal_voc',\n",
    "            \tlabel_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "        \t\tkeymap={\n",
    "            \t\t'img': 'image',\n",
    "            \t\t'gt_bboxes': 'bboxes'\n",
    "        \t\t}),\n",
    "    \tdict(type='YOLOv5HSVRandomAug'),            # HSV通道随机增强\n",
    "    \tdict(type='mmdet.RandomFlip', prob=0.5),        # 随机翻转，翻转概率 0.5\n",
    "    \tdict(\n",
    "        \t\ttype='mmdet.PackDetInputs',         # 将数据转换为检测器输入格式的流程\n",
    "        \t\tmeta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip',\n",
    "                   'flip_direction'))]\n",
    "train_dataloader = dict( # 训练 dataloader 配置\n",
    "    batch_size=train_batch_size_per_gpu, # 训练时单个 GPU 的 Batch size\n",
    "    num_workers=train_num_workers, # 训练时单个 GPU 分配的数据加载线程数\n",
    "    persistent_workers=True, # 如果设置为 True，dataloader 在迭代完一轮之后不会关闭数据读取的子进程，可以加速训练\n",
    "    pin_memory=True, # 开启锁页内存，节省 CPU 内存拷贝时间\n",
    "    sampler=dict( # 训练数据的采样器\n",
    "        type='DefaultSampler', # 默认的采样器，同时支持分布式和非分布式训练。请参考 https://github.com/open-mmlab/mmengine/blob/main/mmengine/dataset/sampler.py\n",
    "        shuffle=True), # 随机打乱每个轮次训练数据的顺序\n",
    "    dataset=dict( # 训练数据集的配置\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file='annotations/instances_train2017.json', # 标注文件路径\n",
    "        data_prefix=dict(img='train2017/'), # 图像路径前缀\n",
    "        filter_cfg=dict(filter_empty_gt=False, min_size=32), # 图像和标注的过滤配置\n",
    "        pipeline=train_pipeline)) # 这是由之前创建的 train_pipeline 定义的数据处理流程\n",
    "\n",
    "# YOLOv5 测试阶段采用 Letter Resize 的方法来将所有的测试图像统一到相同尺度，进而有效保留了图像的长宽比。因此我们在验证和评测时，都采用相同的数据流进行推理。\n",
    "test_pipeline = [ # 测试数据处理流程\n",
    "    dict(\n",
    "        type='LoadImageFromFile', # 第 1 个流程，从文件路径里加载图像\n",
    "        file_client_args=file_client_args),  # 文件读取后端的配置，默认从硬盘读取\n",
    "    dict(type='YOLOv5KeepRatioResize', # 第 2 个流程，保持长宽比的图像大小缩放\n",
    "         scale=img_scale), # 图像缩放的目标尺寸\n",
    "    dict(\n",
    "        type='LetterResize', # 第 3 个流程，满足多种步幅要求的图像大小缩放\n",
    "        scale=img_scale, # 图像缩放的目标尺寸\n",
    "        allow_scale_up=False, # 当 ratio > 1 时，是否允许放大图像，\n",
    "        pad_val=dict(img=114)), # 空区域填充像素值\n",
    "    dict(type='LoadAnnotations', with_bbox=True), # 第 4 个流程，对于当前图像，加载它的注释信息\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs', # 将数据转换为检测器输入格式的流程\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor', 'pad_param'))]\n",
    "val_dataloader = dict(\n",
    "    batch_size=val_batch_size_per_gpu, # 验证时单个 GPU 的 Batch size\n",
    "    num_workers=val_num_workers, # 验证时单个 GPU 分配的数据加载线程数\n",
    "    persistent_workers=True, # 如果设置为 True，dataloader 在迭代完一轮之后不会关闭数据读取的子进程，可以加速训练\n",
    "    pin_memory=True, # 开启锁页内存，节省 CPU 内存拷贝时间\n",
    "    drop_last=False, # 是否丢弃最后未能组成一个批次的数据\n",
    "    sampler=dict(\n",
    "        type='DefaultSampler', # 默认的采样器，同时支持分布式和非分布式训练\n",
    "        shuffle=False), # 验证和测试时不打乱数据顺序\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        test_mode=True, # 开启测试模式，避免数据集过滤图像和标注\n",
    "        data_prefix=dict(img='val2017/'), # 图像路径前缀\n",
    "        ann_file='annotations/instances_val2017.json', # 标注文件路径\n",
    "        pipeline=test_pipeline, # 这是由之前创建的 test_pipeline 定义的数据处理流程\n",
    "        batch_shapes_cfg=dict(  # batch shapes 配置\n",
    "            type='BatchShapePolicy', # 确保在 batch 推理过程中同一个 batch 内的图像 pad 像素最少，不要求整个验证过程中所有 batch 的图像尺度一样\n",
    "            batch_size=val_batch_size_per_gpu, # batch shapes 策略的 batch size，等于验证时单个 GPU 的 Batch size\n",
    "            img_size=img_scale[0], # 图像的尺寸\n",
    "            size_divisor=32, # padding 后的图像的大小应该可以被 pad_size_divisor 整除\n",
    "            extra_pad_ratio=0.5))) # 额外需要 pad 的像素比例\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "# 评测器 用于计算训练模型在验证和测试数据集上的指标。评测器的配置由一个或一组评价指标（Metric）配置组成\n",
    "\n",
    "val_evaluator = dict(  # 验证过程使用的评测器\n",
    "    type='mmdet.CocoMetric',  # 用于评估检测的 AR、AP 和 mAP 的 coco 评价指标\n",
    "    proposal_nums=(100, 1, 10),        # 用于评估检测任务时，选取的Proposal数量\n",
    "    ann_file=data_root + 'annotations/instances_val2017.json',  # 标注文件路径\n",
    "    metric='bbox',  # 需要计算的评价指标，`bbox` 用于检测)test_evaluator = val_evaluator  # 测试过程使用的评测器\n",
    "\n",
    "# 由于测试数据集没有标注文件，因此 MMYOLO 中的 test_dataloader 和 test_evaluator 配置通常等于 val。 如果要保存在测试数据集上的检测结果，则可以像这样编写配置：\n",
    "# 在测试集上推理，# 并将检测结果转换格式以用于提交结果test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "        data_prefix=dict(img='test2017/'),\n",
    "        test_mode=True,\n",
    "        pipeline=test_pipeline))\n",
    "test_evaluator = dict(\n",
    "    type='mmdet.CocoMetric',\n",
    "    ann_file=data_root + 'annotations/image_info_test-dev2017.json',\n",
    "    metric='bbox',\n",
    "    format_only=True,  # 只将模型输出转换为coco的 JSON 格式并保存\n",
    "    outfile_prefix='./work_dirs/coco_detection/test')  # 要保存的 JSON 文件的前缀"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.训练和测试的配置\n",
    "MMEngine 的 Runner 使用 Loop 来控制训练，验证和测试过程。\n",
    "用户可以使用这些字段设置最大训练轮次和验证间隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 300 # 最大训练轮次 300 轮save_epoch_intervals = 10 # 验证间隔，每 10 轮验证一次\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',  # 训练循环的类型，请参考 https://github.com/open-mmlab/mmengine/blob/main/mmengine/runner/loops.py\n",
    "    max_epochs=max_epochs,  # 最大训练轮次 300 轮\n",
    "    val_interval=save_epoch_intervals)  # 验证间隔，每 10 个 epoch 验证一次val_cfg = dict(type='ValLoop')  # 验证循环的类型test_cfg = dict(type='TestLoop')  # 测试循环的类型\n",
    "\n",
    "# MMEngine 也支持动态评估间隔，例如你可以在前面 280 epoch 训练阶段中，每间隔 10 个 epoch 验证一次，到最后 20 epoch 训练中每隔 1 个 epoch 验证一次，则配置写法为：\n",
    "max_epochs = 300 # 最大训练轮次 300 轮save_epoch_intervals = 10 # 验证间隔，每 10 轮验证一次\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',  # 训练循环的类型，请参考 https://github.com/open-mmlab/mmengine/blob/main/mmengine/runner/loops.py\n",
    "    max_epochs=max_epochs,  # 最大训练轮次 300 轮\n",
    "    val_interval=save_epoch_intervals,  # 验证间隔，每 10 个 epoch 验证一次\n",
    "    dynamic_intervals=[(280, 1)]) # 到 280 epoch 开始切换为间隔 1 的评估方式val_cfg = dict(type='ValLoop')  # 验证循环的类型test_cfg = dict(type='TestLoop')  # 测试循环的类型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.优化相关配置\n",
    "optim_wrapper 是配置优化相关设置的字段。优化器封装（OptimWrapper）不仅提供了优化器的功能，还支持梯度裁剪、混合精度训练等功能。  \n",
    "param_scheduler 字段用于配置参数调度器（Parameter Scheduler）来调整优化器的超参数（例如学习率和动量）。 用户可以组合多个调度器来创建所需的参数调整策略。  \n",
    "在 YOLOv5 中，参数调度实现比较复杂，难以 param_scheduler 实现。所以我们采用了 YOLOv5ParamSchedulerHook 来实现（见下节），这样做更简单但是通用性较差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_wrapper = dict(  # 优化器封装的配置\n",
    "    type='OptimWrapper',  # 优化器封装的类型。可以切换至 AmpOptimWrapper 来启用混合精度训练\n",
    "    optimizer=dict(  # 优化器配置。支持 PyTorch 的各种优化器。请参考 https://pytorch.org/docs/stable/optim.html#algorithms\n",
    "        type='SGD',  # 随机梯度下降优化器\n",
    "        lr=0.01,  # 基础学习率\n",
    "        momentum=0.937, # 带动量的随机梯度下降\n",
    "        weight_decay=0.0005, # 权重衰减\n",
    "        nesterov=True, # 开启Nesterov momentum，公式详见 http://www.cs.toronto.edu/~hinton/absps/momentum.pdf\n",
    "        batch_size_per_gpu=train_batch_size_per_gpu),  # 该选项实现了自动权重衰减系数缩放\n",
    "    clip_grad=None,  # 梯度裁剪的配置，设置为 None 关闭梯度裁剪。使用方法请见 https://mmengine.readthedocs.io/en/latest/tutorials/optimizer.html\n",
    "    constructor='YOLOv5OptimizerConstructor') # YOLOv5 优化器构建器"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.钩子配置\n",
    "用户可以在训练、验证和测试循环上添加钩子，以便在运行期间插入一些操作。配置中有两种不同的钩子字段，一种是 default_hooks，另一种是 custom_hooks。  \n",
    "default_hooks 是一个字典，用于配置运行时必须使用的钩子。这些钩子具有默认优先级，如果未设置，runner 将使用默认值。如果要禁用默认钩子，用户可以将其配置设置为 None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_hooks = dict(\n",
    "    param_scheduler=dict(\n",
    "        type='YOLOv5ParamSchedulerHook', # MMYOLO 中默认采用 Hook 方式进行优化器超参数的调节\n",
    "        scheduler_type='linear',\n",
    "        lr_factor=0.01,\n",
    "        max_epochs=max_epochs),\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook', # 按照给定间隔保存模型的权重的 Hook\n",
    "        interval=save_epoch_intervals, # 每 10 轮保存 1 次权重文件\n",
    "        max_keep_ckpts=3)) # 最多保存 3 个权重文件\n",
    "\n",
    "# custom_hooks 是一个列表。用户可以在这个字段中加入自定义的钩子，例如 EMAHook。\n",
    "custom_hooks = [\n",
    "    dict(\n",
    "        type='EMAHook', # 实现权重 EMA(指数移动平均) 更新的 Hook\n",
    "        ema_type='ExpMomentumEMA', # YOLO 中使用的带动量 EMA\n",
    "        momentum=0.0001, # EMA 的动量参数\n",
    "        update_buffers=True, # 是否计算模型的参数和缓冲的 running averages\n",
    "        priority=49) # 优先级略高于 NORMAL(50)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.运行相关配置\n",
    "default_runtime.py 中的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scope = 'mmyolo'  # 默认的注册器域名，默认从此注册器域中寻找模块。请参考 https://mmengine.readthedocs.io/en/latest/tutorials/registry.html\n",
    "env_cfg = dict(\n",
    "    cudnn_benchmark=True,  # 是否启用 cudnn benchmark, 推荐单尺度训练时开启，可加速训练\n",
    "    mp_cfg=dict(  # 多进程设置\n",
    "        mp_start_method='fork',  # 使用 fork 来启动多进程。‘fork’ 通常比 ‘spawn’ 更快，但可能存在隐患。请参考 https://github.com/pytorch/pytorch/issues/1355\n",
    "        opencv_num_threads=0),  # 关闭 opencv 的多线程以避免系统超负荷\n",
    "    dist_cfg=dict(backend='nccl'),  # 分布式相关设置)\n",
    "vis_backends = [dict(type='LocalVisBackend')]  # 可视化后端，请参考 https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/visualization.html\n",
    "visualizer = dict(\n",
    "    type='mmdet.DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')log_processor = dict(\n",
    "    type='LogProcessor',  # 日志处理器用于处理运行时日志\n",
    "    window_size=50,  # 日志数值的平滑窗口\n",
    "    by_epoch=True)  # 是否使用 epoch 格式的日志。需要与训练循环的类型保存一致。\n",
    "log_level = 'INFO'  # 日志等级load_from = None  # 从给定路径加载模型检查点作为预训练模型。这不会恢复训练。resume = False  # 是否从 `load_from` 中定义的检查点恢复。 如果 `load_from` 为 None，它将恢复 `work_dir` 中的最新检查点。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.使用配置文件里的中间变量\n",
    "配置文件里会使用一些中间变量，例如数据集里的 train_pipeline/test_pipeline。我们在定义新的 \ttrain_pipeline/test_pipeline 之后，需要将它们传递到 data 里。例如，我们想在训练或测试时，改变 YOLOv5 网络的 img_scale 训练尺度并在训练时添加 YOLOv5MixUp 数据增强，img_scale/train_pipeline/test_pipeline 是我们想要修改的中间变量。  \n",
    "中间变量必须传入字典才能生效。经常有同学问，修改了最上面的 img_scale 或者 max_epochs 怎么没有生效。  \n",
    "注：使用 YOLOv5MixUp 数据增强时，需要将 YOLOv5MixUp 之前的训练数据处理流程定义在其 pre_transform 中。详细过程和图解可参见 YOLOv5 原理和实现全解析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = './yolov5_s-v61_syncbn_8xb16-300e_coco.py'\n",
    "img_scale = (1280, 1280)  # 高度，宽度affine_scale = 0.9        # 仿射变换尺度\n",
    "mosaic_affine_pipeline = [\n",
    "    dict(\n",
    "        type='Mosaic',\n",
    "        img_scale=img_scale,\n",
    "        pad_val=114.0,\n",
    "        pre_transform=pre_transform),\n",
    "    dict(\n",
    "        type='YOLOv5RandomAffine',\n",
    "        max_rotate_degree=0.0,\n",
    "        max_shear_degree=0.0,\n",
    "        scaling_ratio_range=(1 - affine_scale, 1 + affine_scale),\n",
    "        border=(-img_scale[0] // 2, -img_scale[1] // 2),\n",
    "        border_val=(114, 114, 114))]\n",
    "train_pipeline = [\n",
    "    *pre_transform, *mosaic_affine_pipeline,\n",
    "    dict(\n",
    "        type='YOLOv5MixUp',        # YOLOv5 的 MixUp (图像混合) 数据增强\n",
    "        prob=0.1, # MixUp 概率\n",
    "        pre_transform=[*pre_transform,*mosaic_affine_pipeline]), # MixUp 之前的训练数据处理流程，包含 数据预处理流程、 'Mosaic' 和 'YOLOv5RandomAffine'\n",
    "    dict(\n",
    "        type='mmdet.Albu',\n",
    "        transforms=albu_train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            'gt_bboxes': 'bboxes'\n",
    "        }),\n",
    "    dict(type='YOLOv5HSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip',\n",
    "                   'flip_direction'))]\n",
    "test_pipeline = [\n",
    "    dict(\n",
    "        type='LoadImageFromFile',\n",
    "        file_client_args={{_base_.file_client_args}}),\n",
    "    dict(type='YOLOv5KeepRatioResize', scale=img_scale),\n",
    "    dict(\n",
    "        type='LetterResize',\n",
    "        scale=img_scale,\n",
    "        allow_scale_up=False,\n",
    "        pad_val=dict(img=114)),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor', 'pad_param'))]\n",
    "train_dataloader = dict(dataset=dict(pipeline=train_pipeline))val_dataloader = dict(dataset=dict(pipeline=test_pipeline))test_dataloader = dict(dataset=dict(pipeline=test_pipeline))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用脚本命令\n",
    "### demo/ 演示脚本  \n",
    "demo/boxam_vis_demo.py CAM 可视化  \n",
    "demo/deploy_demo.py mmdeploy 推理示例  \n",
    "demo/featmap_vis_demo.py 特征图可视化  \n",
    "demo/image_demo.py 普通图片推理示例  \n",
    "demo/large_image_demo.py 大图推理示例（基于 SAHI）  \n",
    "demo/video_demo.py 视频推理示例  \n",
    "### tools/ 训练和测试  \n",
    "tools/dist_test.sh 多卡测试  \n",
    "tools/dist_train.sh 多卡训练  \n",
    "tools/slurm_test.sh Slurm 集群测试  \n",
    "tools/slurm_train.sh Slurm 集群训练  \n",
    "tools/test.py 单卡测试  \n",
    "tools/train.py 单卡训练  \n",
    "### tools/analysis_tools/ 分析工具  \n",
    "tools/analysis_tools/benchmark.py 推理速度测试基准  \n",
    "tools/analysis_tools/browse_coco_json.py 可视化 COCO JSON 标签文件  \n",
    "tools/analysis_tools/browse_dataset.py 可视化数据集  \n",
    "tools/analysis_tools/dataset_analysis.py 数据集统计分析  \n",
    "tools/analysis_tools/optimize_anchors.py 优化锚框尺寸  \n",
    "### tools/dataset_converters/ 数据集转换  \n",
    "tools/dataset_converters/balloon2coco.py Balloon 数据集转 COCO 格式  \n",
    "tools/dataset_converters/labelme2coco.py Labelme 标注转 COCO 格式  \n",
    "tools/dataset_converters/yolo2coco.py YOLO .txt 标注转 COCO 格式  \n",
    "### tools/misc/ 其他  \n",
    "tools/misc/coco_split.py COCO 数据集划分  \n",
    "tools/misc/download_dataset.py 下载数据集  \n",
    "tools/misc/extract_subcoco.py 提取 COCO 子集  \n",
    "### tools/model_converters/ 官方仓库模型转换至 MMYOLO 模型  \n",
    "tools/model_converters/rtmdet_to_mmyolo.py 转换 RTMDet 模型  \n",
    "tools/model_converters/ppyoloe_to_mmyolo.py 转换 PPYOLO-E 模型  \n",
    "tools/model_converters/yolov5_to_mmyolo.py 转换 YOLOv5 模型  \n",
    "tools/model_converters/yolov6_to_mmyolo.py 转换 YOLOv6 模型  \n",
    "tools/model_converters/yolov7_to_mmyolo.py 转换 YOLOv7 模型  \n",
    "tools/model_converters/yolov8_to_mmyolo.py 转换 YOLOv8 模型  \n",
    "tools/model_converters/yolox_to_mmyolo.py 转换 YOLOX 模型  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型分析步骤  \n",
    "完整步骤如下：  \n",
    "数据集准备：tools/misc/download_dataset.py  \n",
    "使用 labelme 和算法进行辅助标注：demo/image_demo.py + labelme  \n",
    "使用脚本转换成 COCO 数据集格式：tools/dataset_converters/labelme2coco.py  \n",
    "数据集划分为训练集、验证集和测试集：tools/misc/coco_split.py  \n",
    "构建 config 文件  \n",
    "数据集可视化分析：tools/analysis_tools/dataset_analysis.py  \n",
    "优化 anchor 尺寸：tools/analysis_tools/optimize_anchors.py  \n",
    "可视化数据处理部分：tools/analysis_tools/browse_dataset.py  \n",
    "启动训练：tools/train.py  \n",
    "模型推理：demo/image_demo.py  \n",
    "模型部署  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日志中model后面的配置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albu_train_transforms = [\n",
    "    dict(type='Blur', p=0.01),\n",
    "    dict(type='MedianBlur', p=0.01),\n",
    "    dict(type='ToGray', p=0.01),\n",
    "    dict(type='CLAHE', p=0.01)\n",
    "]\n",
    "pre_transform = [\n",
    "    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),\n",
    "    dict(type='LoadAnnotations', with_bbox=True)\n",
    "]\n",
    "last_transform = [\n",
    "    dict(\n",
    "        type='mmdet.Albu',\n",
    "        transforms=[\n",
    "            dict(type='Blur', p=0.01),\n",
    "            dict(type='MedianBlur', p=0.01),\n",
    "            dict(type='ToGray', p=0.01),\n",
    "            dict(type='CLAHE', p=0.01)\n",
    "        ],\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "        keymap=dict(img='image', gt_bboxes='bboxes')),\n",
    "    dict(type='YOLOv5HSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip',\n",
    "                   'flip_direction'))\n",
    "]\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Mosaic',\n",
    "        img_scale=(640, 640),\n",
    "        pad_val=114.0,\n",
    "        pre_transform=[\n",
    "            dict(\n",
    "                type='LoadImageFromFile',\n",
    "                file_client_args=dict(backend='disk')),\n",
    "            dict(type='LoadAnnotations', with_bbox=True)\n",
    "        ]),\n",
    "    dict(\n",
    "        type='YOLOv5RandomAffine',\n",
    "        max_rotate_degree=0.0,\n",
    "        max_shear_degree=0.0,\n",
    "        scaling_ratio_range=(0.5, 1.5),\n",
    "        max_aspect_ratio=100,\n",
    "        border=(-320, -320),\n",
    "        border_val=(114, 114, 114)),\n",
    "    dict(\n",
    "        type='mmdet.Albu',\n",
    "        transforms=[\n",
    "            dict(type='Blur', p=0.01),\n",
    "            dict(type='MedianBlur', p=0.01),\n",
    "            dict(type='ToGray', p=0.01),\n",
    "            dict(type='CLAHE', p=0.01)\n",
    "        ],\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "        keymap=dict(img='image', gt_bboxes='bboxes')),\n",
    "    dict(type='YOLOv5HSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip',\n",
    "                   'flip_direction'))\n",
    "]\n",
    "train_pipeline_stage2 = [\n",
    "    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='YOLOv5KeepRatioResize', scale=(640, 640)),\n",
    "    dict(\n",
    "        type='LetterResize',\n",
    "        scale=(640, 640),\n",
    "        allow_scale_up=True,\n",
    "        pad_val=dict(img=114.0)),\n",
    "    dict(\n",
    "        type='YOLOv5RandomAffine',\n",
    "        max_rotate_degree=0.0,\n",
    "        max_shear_degree=0.0,\n",
    "        scaling_ratio_range=(0.5, 1.5),\n",
    "        max_aspect_ratio=100,\n",
    "        border_val=(114, 114, 114)),\n",
    "    dict(\n",
    "        type='mmdet.Albu',\n",
    "        transforms=[\n",
    "            dict(type='Blur', p=0.01),\n",
    "            dict(type='MedianBlur', p=0.01),\n",
    "            dict(type='ToGray', p=0.01),\n",
    "            dict(type='CLAHE', p=0.01)\n",
    "        ],\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "        keymap=dict(img='image', gt_bboxes='bboxes')),\n",
    "    dict(type='YOLOv5HSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'flip',\n",
    "                   'flip_direction'))\n",
    "]\n",
    "train_dataloader = dict(\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    collate_fn=dict(type='yolov5_collate'),\n",
    "    dataset=dict(\n",
    "        type='RepeatDataset',\n",
    "        times=5,\n",
    "        dataset=dict(\n",
    "            type='YOLOv5CocoDataset',\n",
    "            data_root='./data/rip_gd/',\n",
    "            metainfo=dict(classes=('with_rips', ), palette=[(220, 20, 60)]),\n",
    "            ann_file='annotations/trainval.json',\n",
    "            data_prefix=dict(img='images/'),\n",
    "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
    "            pipeline=[\n",
    "                dict(\n",
    "                    type='LoadImageFromFile',\n",
    "                    file_client_args=dict(backend='disk')),\n",
    "                dict(type='LoadAnnotations', with_bbox=True),\n",
    "                dict(\n",
    "                    type='Mosaic',\n",
    "                    img_scale=(640, 640),\n",
    "                    pad_val=114.0,\n",
    "                    pre_transform=[\n",
    "                        dict(\n",
    "                            type='LoadImageFromFile',\n",
    "                            file_client_args=dict(backend='disk')),\n",
    "                        dict(type='LoadAnnotations', with_bbox=True)\n",
    "                    ]),\n",
    "                dict(\n",
    "                    type='YOLOv5RandomAffine',\n",
    "                    max_rotate_degree=0.0,\n",
    "                    max_shear_degree=0.0,\n",
    "                    scaling_ratio_range=(0.5, 1.5),\n",
    "                    max_aspect_ratio=100,\n",
    "                    border=(-320, -320),\n",
    "                    border_val=(114, 114, 114)),\n",
    "                dict(\n",
    "                    type='mmdet.Albu',\n",
    "                    transforms=[\n",
    "                        dict(type='Blur', p=0.01),\n",
    "                        dict(type='MedianBlur', p=0.01),\n",
    "                        dict(type='ToGray', p=0.01),\n",
    "                        dict(type='CLAHE', p=0.01)\n",
    "                    ],\n",
    "                    bbox_params=dict(\n",
    "                        type='BboxParams',\n",
    "                        format='pascal_voc',\n",
    "                        label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "                    keymap=dict(img='image', gt_bboxes='bboxes')),\n",
    "                dict(type='YOLOv5HSVRandomAug'),\n",
    "                dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "                dict(\n",
    "                    type='mmdet.PackDetInputs',\n",
    "                    meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                               'flip', 'flip_direction'))\n",
    "            ])))\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),\n",
    "    dict(type='YOLOv5KeepRatioResize', scale=(640, 640)),\n",
    "    dict(\n",
    "        type='LetterResize',\n",
    "        scale=(640, 640),\n",
    "        allow_scale_up=False,\n",
    "        pad_val=dict(img=114)),\n",
    "    dict(type='LoadAnnotations', with_bbox=True, _scope_='mmdet'),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor', 'pad_param'))\n",
    "]\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type='YOLOv5CocoDataset',\n",
    "        data_root='./data/rip_gd/',\n",
    "        test_mode=True,\n",
    "        data_prefix=dict(img='images/'),\n",
    "        ann_file='annotations/trainval.json',\n",
    "        pipeline=[\n",
    "            dict(\n",
    "                type='LoadImageFromFile',\n",
    "                file_client_args=dict(backend='disk')),\n",
    "            dict(type='YOLOv5KeepRatioResize', scale=(640, 640)),\n",
    "            dict(\n",
    "                type='LetterResize',\n",
    "                scale=(640, 640),\n",
    "                allow_scale_up=False,\n",
    "                pad_val=dict(img=114)),\n",
    "            dict(type='LoadAnnotations', with_bbox=True, _scope_='mmdet'),\n",
    "            dict(\n",
    "                type='mmdet.PackDetInputs',\n",
    "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                           'scale_factor', 'pad_param'))\n",
    "        ],\n",
    "        batch_shapes_cfg=None,\n",
    "        metainfo=dict(classes=('with_rips', ), palette=[(220, 20, 60)])))\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type='YOLOv5CocoDataset',\n",
    "        data_root='./data/rip_gd/',\n",
    "        test_mode=True,\n",
    "        data_prefix=dict(img='images/'),\n",
    "        ann_file='annotations/trainval.json',\n",
    "        pipeline=[\n",
    "            dict(\n",
    "                type='LoadImageFromFile',\n",
    "                file_client_args=dict(backend='disk')),\n",
    "            dict(type='YOLOv5KeepRatioResize', scale=(640, 640)),\n",
    "            dict(\n",
    "                type='LetterResize',\n",
    "                scale=(640, 640),\n",
    "                allow_scale_up=False,\n",
    "                pad_val=dict(img=114)),\n",
    "            dict(type='LoadAnnotations', with_bbox=True, _scope_='mmdet'),\n",
    "            dict(\n",
    "                type='mmdet.PackDetInputs',\n",
    "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                           'scale_factor', 'pad_param'))\n",
    "        ],\n",
    "        batch_shapes_cfg=None,\n",
    "        metainfo=dict(classes=('with_rips', ), palette=[(220, 20, 60)])))\n",
    "param_scheduler = None\n",
    "optim_wrapper = dict(\n",
    "    type='OptimWrapper',\n",
    "    clip_grad=dict(max_norm=10.0),\n",
    "    optimizer=dict(\n",
    "        type='SGD',\n",
    "        lr=0.0025,\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.0005,\n",
    "        nesterov=True,\n",
    "        batch_size_per_gpu=16),\n",
    "    constructor='YOLOv5OptimizerConstructor')\n",
    "custom_hooks = [\n",
    "    dict(\n",
    "        type='EMAHook',\n",
    "        ema_type='ExpMomentumEMA',\n",
    "        momentum=0.0001,\n",
    "        update_buffers=True,\n",
    "        strict_load=False,\n",
    "        priority=49),\n",
    "    dict(\n",
    "        type='mmdet.PipelineSwitchHook',\n",
    "        switch_epoch=490,\n",
    "        switch_pipeline=[\n",
    "            dict(\n",
    "                type='LoadImageFromFile',\n",
    "                file_client_args=dict(backend='disk')),\n",
    "            dict(type='LoadAnnotations', with_bbox=True),\n",
    "            dict(type='YOLOv5KeepRatioResize', scale=(640, 640)),\n",
    "            dict(\n",
    "                type='LetterResize',\n",
    "                scale=(640, 640),\n",
    "                allow_scale_up=True,\n",
    "                pad_val=dict(img=114.0)),\n",
    "            dict(\n",
    "                type='YOLOv5RandomAffine',\n",
    "                max_rotate_degree=0.0,\n",
    "                max_shear_degree=0.0,\n",
    "                scaling_ratio_range=(0.5, 1.5),\n",
    "                max_aspect_ratio=100,\n",
    "                border_val=(114, 114, 114)),\n",
    "            dict(\n",
    "                type='mmdet.Albu',\n",
    "                transforms=[\n",
    "                    dict(type='Blur', p=0.01),\n",
    "                    dict(type='MedianBlur', p=0.01),\n",
    "                    dict(type='ToGray', p=0.01),\n",
    "                    dict(type='CLAHE', p=0.01)\n",
    "                ],\n",
    "                bbox_params=dict(\n",
    "                    type='BboxParams',\n",
    "                    format='pascal_voc',\n",
    "                    label_fields=['gt_bboxes_labels', 'gt_ignore_flags']),\n",
    "                keymap=dict(img='image', gt_bboxes='bboxes')),\n",
    "            dict(type='YOLOv5HSVRandomAug'),\n",
    "            dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "            dict(\n",
    "                type='mmdet.PackDetInputs',\n",
    "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                           'flip', 'flip_direction'))\n",
    "        ])\n",
    "]\n",
    "val_evaluator = dict(\n",
    "    type='mmdet.CocoMetric',\n",
    "    proposal_nums=(100, 1, 10),\n",
    "    ann_file='./data/rip_gd/annotations/trainval.json',\n",
    "    metric='bbox')\n",
    "test_evaluator = dict(\n",
    "    type='mmdet.CocoMetric',\n",
    "    proposal_nums=(100, 1, 10),\n",
    "    ann_file='./data/rip_gd/annotations/trainval.json',\n",
    "    metric='bbox')\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',\n",
    "    max_epochs=30,\n",
    "    val_interval=2,\n",
    "    dynamic_intervals=[(490, 1)],\n",
    "    val_begin=20)\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "work_dir = './work_dirs/yolov8_s_syncbn_fast_1xb32-30e_cat'\n",
    "anchors = [[(68, 69), (154, 91), (143, 162)],\n",
    "           [(242, 160), (189, 287), (391, 207)],\n",
    "           [(353, 337), (539, 341), (443, 432)]]\n",
    "class_name = ('with_rips', )\n",
    "metainfo = dict(classes=('with_rips', ), palette=[(220, 20, 60)])\n",
    "launcher = 'none'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8bbe02d581d775bc26cee01ced8e729d24ff8d7a7d0943d80dbc1513ec3bd46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
